{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, key, sequence):\n",
    "        self.key = key\n",
    "        self.sequence = sequence\n",
    "        self.next = []\n",
    "        self.last = []\n",
    "\n",
    "    def link_nexts(self, n_next):\n",
    "        self.next.append(n_next)\n",
    "        n_next.link_last(self)\n",
    "    \n",
    "    def link_last(self, n_last):\n",
    "        self.last.append(n_last)\n",
    "    \n",
    "    def set_sequence(self, sequence):\n",
    "        self.sequence = sequence\n",
    "    def __repr__(self):\n",
    "        return \"<<s:{} n:{}>>\".format(self.sequence, self.next)\n",
    "        \n",
    "class Sequemem:\n",
    "    def __init__(self, uuid):\n",
    "        self.uuid = uuid\n",
    "        self.n_init = Neuron('<init>', '<start>')\n",
    "        self.layer = defaultdict(list)\n",
    "        self.predicted = []\n",
    "        self.active = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.predicted = self.n_init.next[:]\n",
    "        self.active = [self.n_init]\n",
    "    \n",
    "    def predict(self, str_sentence):\n",
    "        self.reset()\n",
    "        words = self.get_word_array(str_sentence)\n",
    "        for idx, word in enumerate(words):\n",
    "            current_active = self.active[:]\n",
    "            if self.hit(word):\n",
    "                continue\n",
    "            else:\n",
    "                neuron =  Neuron(word, \"#\".join(words[:(idx+1)]))\n",
    "                self.layer[word] = neuron\n",
    "                for n in current_active:\n",
    "                    n.link_nexts(neuron)\n",
    "                  \n",
    "        return [neuron.key for neuron in self.predicted]\n",
    "            \n",
    "        \n",
    "    def get_word_array(self, str_sentence):\n",
    "        return re.compile(r'\\w+').findall(str_sentence)\n",
    "    \n",
    "    def hit(self, word):\n",
    "        # First for this word, move all hits to active\n",
    "        while len(self.predicted) != 0:\n",
    "            neuron = self.predicted.pop()\n",
    "            if neuron.key == word:\n",
    "                self.active.append(neuron)\n",
    "        \n",
    "        # Second, take any actives and set their nexts to predicted\n",
    "        self.predicted = [n for neuron in self.active if neuron.next for n in neuron.next]\n",
    "            \n",
    "        # IF we have any predicts, we're good, else signal end\n",
    "        return True if len(self.predicted) > 0 else False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}\\n{}\\n{}\\n{}\\n{}\\n\".format(\n",
    "            self.uuid,\n",
    "            self.n_init,\n",
    "            self.layer,\n",
    "            self.predicted,\n",
    "            self.active\n",
    "        )\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', '22']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = Sequemem('adz')\n",
    "seq.get_word_array(\"The quick brown fox 22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.predict(\"The quick brown fox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adz\n",
       "<<s:<start> n:[<<s:The n:[]>>]>>\n",
       "defaultdict(<type 'list'>, {'The': <<s:The n:[]>>})\n",
       "[<<s:The n:[]>>]\n",
       "[<<s:<start> n:[<<s:The n:[]>>]>>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting:  data/00_clean/sent_alice_in_wonderland.txt\n",
      "Loading file data/00_clean/sent_alice_in_wonderland.txt\n",
      "0\n",
      "starting:  data/00_clean/sent_andersens_fairy_tales_pg1597.txt\n",
      "Loading file data/00_clean/sent_andersens_fairy_tales_pg1597.txt\n",
      "0\n",
      "starting:  data/00_clean/sent_cats_of_ulthar.txt\n",
      "Loading file data/00_clean/sent_cats_of_ulthar.txt\n",
      "0\n",
      "starting:  data/00_clean/sent_fairy_tales.txt\n",
      "Loading file data/00_clean/sent_fairy_tales.txt\n",
      "0\n",
      "starting:  data/00_clean/sent_grimms_fairy_tales.txt\n",
      "Loading file data/00_clean/sent_grimms_fairy_tales.txt\n",
      "0\n",
      "starting:  data/00_clean/sent_iris_fairy_tales.txt\n",
      "Loading file data/00_clean/sent_iris_fairy_tales.txt\n",
      "0\n",
      "starting:  data/00_clean/sent_jungle_book_236-0.txt\n",
      "Loading file data/00_clean/sent_jungle_book_236-0.txt\n",
      "0\n",
      "starting:  data/00_clean/sent_king_james_bible.txt\n",
      "Loading file data/00_clean/sent_king_james_bible.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "starting:  data/00_clean/sent_shakespear.txt\n",
      "Loading file data/00_clean/sent_shakespear.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "starting:  data/00_clean/sent_tao_te_king.txt\n",
      "Loading file data/00_clean/sent_tao_te_king.txt\n",
      "0\n",
      "starting:  data/00_clean/sent_the_prince.txt\n",
      "Loading file data/00_clean/sent_the_prince.txt\n",
      "0\n",
      "starting:  data/00_clean/sent_thousand_and_one.txt\n",
      "Loading file data/00_clean/sent_thousand_and_one.txt\n",
      "0\n",
      "starting:  data/00_clean/sents_fables_la_fontaine.txt\n",
      "Loading file data/00_clean/sents_fables_la_fontaine.txt\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "layer = LayerCount()\n",
    "\n",
    "files = [\n",
    "   'data/00_clean/sent_alice_in_wonderland.txt',\n",
    "   'data/00_clean/sent_andersens_fairy_tales_pg1597.txt',\n",
    "   'data/00_clean/sent_cats_of_ulthar.txt',\n",
    "   'data/00_clean/sent_fairy_tales.txt',\n",
    "   'data/00_clean/sent_grimms_fairy_tales.txt',\n",
    "   'data/00_clean/sent_iris_fairy_tales.txt',\n",
    "   'data/00_clean/sent_jungle_book_236-0.txt',\n",
    "   'data/00_clean/sent_king_james_bible.txt',\n",
    "   'data/00_clean/sent_shakespear.txt',\n",
    "   'data/00_clean/sent_tao_te_king.txt',\n",
    "   'data/00_clean/sent_the_prince.txt',\n",
    "   'data/00_clean/sent_thousand_and_one.txt',\n",
    "   'data/00_clean/sents_fables_la_fontaine.txt',\n",
    "]\n",
    "\n",
    "for f in files:\n",
    "    print(\"starting: \", f)\n",
    "    layer.load_from_file(f, lower=True)\n",
    "\n",
    "layer.get_frequency_dict();\n",
    "print(\"All Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-iitializing dictionary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.999999999990909"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.jaccard('king','king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marcellus',\n",
       " 'horatio',\n",
       " 'enter',\n",
       " 'it',\n",
       " 'bernardo',\n",
       " 'watch',\n",
       " 'officer',\n",
       " 'myself',\n",
       " 'bell',\n",
       " 'then',\n",
       " 'beating',\n",
       " 'burns',\n",
       " 'now',\n",
       " 'where',\n",
       " 'heaven',\n",
       " 'part',\n",
       " 'illume',\n",
       " 'caius',\n",
       " 'wife',\n",
       " 'she',\n",
       " 'sir',\n",
       " 'true',\n",
       " 'stop',\n",
       " 'speak',\n",
       " 'stay',\n",
       " 'on']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.comparison_frequencies('marcellus',window_size=10,ratio=0.75,cutoff=25)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "def save_compare_freqs_to_file(window_size, ratio=0.9, cutoff=25):\n",
    "    w = str(window_size)\n",
    "    r = str(ratio).replace('.', '_')\n",
    "    c = str(cutoff)\n",
    "    with open('word_compare_freqs_size_{}_ratio_{}_cutoff_{}.csv'.format(w, r,c), 'w') as target:\n",
    "        for word in layer.d_w_uber_freq.keys():\n",
    "            lst_wrds = layer.comparison_frequencies(word, window_size=window_size,ratio=ratio, cutoff=cutoff)[2]\n",
    "            target.write(\"{}\\t{}\\n\".format(word, \"\\t\".join(lst_wrds)))\n",
    "\n",
    "save_compare_freqs_to_file(15)            \n",
    "print(\"All Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict loaded!\n"
     ]
    }
   ],
   "source": [
    "def load_word_from_line(line, d):\n",
    "    \"\"\"asume tab separated lines\"\"\"\n",
    "    words = line.split('\\t')\n",
    "    d[words.pop(0)] = words\n",
    "        \n",
    "word_5 = {}\n",
    "with open('word_compare_freqs_size_15_ratio_0_9_cutoff_25.csv', 'r') as source:\n",
    "    for line in source:\n",
    "        load_word_from_line(line, word_5)\n",
    "\n",
    "print(\"dict loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_local(lst1, lst2):\n",
    "    \"\"\"Calculate jaccard distance between two words from their graphical representation\n",
    "    as calculated with window_size and ratio.  Keep the number of cutoff words for the calculation.\n",
    "    Args:\n",
    "        w1: string, the first word for comparison\n",
    "        w2: string, the second word for comparison\n",
    "        window_size: int, go +- this number of words to calculate frequencies for graphical calc.\n",
    "        ratio: float, use this as cutoff in graphical calculation\n",
    "        cutoff: int, from graphical calculation, keep this number of words, the jaccard distance\n",
    "                is then calculated as the overlap of these two sets.\n",
    "    \"\"\"\n",
    "\n",
    "    u = len(set(lst1).union(set(lst2))) + 0.0000000001\n",
    "    i = len(set(lst1).intersection(set(lst2)))\n",
    "    return float(i)/float(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "across 0.5294117647043253\n",
      "ali 0.5294117647043253\n",
      "baba 0.5294117647043253\n",
      "looked 0.5294117647043253\n",
      "mustapha 0.5294117647043253\n",
      "perceiving 0.5294117647043253\n",
      "trying 0.5294117647043253\n"
     ]
    }
   ],
   "source": [
    "bust = 0\n",
    "threshold = 0.50\n",
    "w1 = 'morgiana'\n",
    "w1nbors = word_5[w1]\n",
    "best_matches = []\n",
    "for word, nbors in word_5.items():\n",
    "\n",
    "    if word == w1:\n",
    "        continue\n",
    "\n",
    "    score = jaccard_local(nbors, w1nbors)\n",
    "    if score > threshold:\n",
    "        print(word,score)\n",
    "        best_matches.append((word,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 3574),\n",
       " ('of', 1184),\n",
       " ('and', 431),\n",
       " ('henry', 402),\n",
       " ('richard', 277),\n",
       " ('edward', 149),\n",
       " ('john', 124),\n",
       " ('said', 118),\n",
       " ('s', 112),\n",
       " ('that', 103)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.get_counts_for_specific_key(key='king', window_size=2, direction=1).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wolf', 'father', 'mother', 'lone', 'sir', 'pack', 'ran', 'whose', 'seeonee', 's', 'replied', 'ravenous', 'got', 'shook', 'sleeping', 'stole']\n",
      "['wolf', 'a', 'said', 'father', 'mother', 'or', 'lone', 'sir', 'replied', 'pack', 'ran', 'dead', 'himself', 'lay', 'fox', 'whose']\n",
      "['wolf', 'a', 'said', 'father', 'mother', 'had', 'or', 'would', 'fox', 'lone', 'sir', 'replied', 'pack', 'himself', 'ran', 'bear']\n",
      "['wolf', 'the', 'a', 'said', 'father', 'had', 'mother', 'would', 'fox', 'or', 'lone', 'pack', 'into', 'sir', 'replied', 'himself']\n",
      "['wolf', 'the', 'a', 'said', 'father', 'had', 'mother', 'would', 'fox', 'or', 'if', 'up', 'who', 'pack', 'lone', 'sheep']\n",
      "['the', 'wolf', 'a', 'said', 'as', 'father', 'had', 'mother', 'would', 'or', 'fox', 'if', 'up', 'who', 'pack', 'sheep']\n",
      "['the', 'wolf', 'a', 'his', 'said', 'as', 'father', 'had', 'was', 'would', 'mother', 'fox', 'or', 'if', 'at', 'up']\n",
      "['the', 'wolf', 'a', 'to', 'he', 'his', 'said', 'as', 'had', 'was', 'father', 'but', 'mother', 'or', 'fox', 'would']\n",
      "['the', 'wolf', 'a', 'to', 'in', 'he', 'his', 'said', 'as', 'was', 'had', 'father', 'but', 'mother', 'would', 'or']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'in', 'his', 'said', 'as', 'you', 'was', 'had', 'but', 'him', 'father']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'in', 'his', 'said', 'as', 'was', 'you', 'had', 'but', 'him', 'father']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'in', 'his', 'that', 'said', 'as', 'you', 'with', 'was', 'not', 'but']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'in', 'his', 'that', 'said', 'as', 'was', 'you', 'with', 'not', 'but']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'his', 'in', 'that', 'said', 'as', 'with', 'was', 'you', 'not', 'for']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'his', 'in', 'that', 'said', 'as', 'was', 'with', 'you', 'not', 'for']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'his', 'in', 'that', 'said', 'as', 'was', 'with', 'not', 'you', 'for']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'his', 'in', 'that', 'said', 'was', 'as', 'with', 'not', 'you', 'for']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'his', 'in', 'that', 'said', 'was', 'as', 'with', 'not', 'you', 'but']\n"
     ]
    }
   ],
   "source": [
    "for idx in range(2,20):\n",
    "    print(layer.comparison_frequencies('wolf',window_size=idx,ratio=0.9,cutoff=15)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39598\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'jaccard' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3726c3e12d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frequency_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_wdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_wdx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwindow_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jaccard' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#layer.get_counts_for_specific_key('fox').most_common()\n",
    "layer.window_size = 1\n",
    "layer.get_frequency_dict()\n",
    "\n",
    "cutoff = 100\n",
    "ratio = 0.25\n",
    "window_range = [10,15]\n",
    "w1 = 'god'\n",
    "w2 = 'jesus'\n",
    "print(len(layer.get_frequency_dict()[1]))\n",
    "\n",
    "profile = [jaccard(w1, w2, _w=_wdx, _c=cutoff, _r=ratio) for _wdx in window_range];\n",
    "print(profile)\n",
    "plt.axis([0, len(window_range), 0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 100\n",
    "ratio = 0.15\n",
    "window_range = 10\n",
    "w1 = 'queen'\n",
    "_,_,lst = layer.comparison_frequencies(w1, window_size=window_range,ratio=ratio, cutoff=cutoff)\n",
    "print(lst[:10])\n",
    "words = layer.get_frequency_dict()[1].keys()\n",
    "print(len(words))\n",
    "high = 0\n",
    "best_matches = []\n",
    "bust = 0\n",
    "threshold = 0.019\n",
    "for word in words:\n",
    "    bust += 1\n",
    "    if word == w1:\n",
    "        continue\n",
    "\n",
    "    score = jaccard(w1, word, _w=window_range, _c=cutoff, _r=ratio)\n",
    "    if bust % 10000 == 0: print(\"progress: \",bust)\n",
    "    if score > threshold:\n",
    "        print(word,score)\n",
    "        best_matches.append((word,score))\n",
    "        \n",
    "print(\"Best match is {} with a score of {}\".format(best_match, high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(len(layer.get_frequency_dict()[1]))\n",
    "a = np.random.random((128, 128))\n",
    "plt.imshow(a, cmap='hot', interpolation='nearest')\n",
    "plt.show()\n",
    "layer.get_frequency_dict()[1][\"Jesus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.get_frequency_dict()[1][\"Jesus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['a','b','c']\n",
    "var = l.pop(0)\n",
    "r = l[:]\n",
    "l.pop(0)\n",
    "l\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt, dct = layer.initialize_frequency_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison_frequencies\n",
    "layer.comparison_frequencies('men', ratio=0.5, cutoff=50, visualize_it=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.get_counts_for_specific_key('love').most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head_keys = layer.columns.keys()\n",
    "# neurons = list({neuron for column in layer.columns.values() for neuron in column})\n",
    "# one_hot_raw = np.eye(len(head_keys), dtype=int)\n",
    "# len(one_hot_raw)\n",
    "# d_head_keys = {}\n",
    "# for idx, word in enumerate(head_keys):\n",
    "#     d_head_keys[word] = one_hot_raw[idx]\n",
    "# len(d_head_keys)\n",
    "# ar_sent_vecs = np.zeros((len(neurons),len(head_keys)))\n",
    "# ar_sent_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headkeys = layer.columns.keys()\n",
    "# neurons = list({neuron for column in layer.columns.values() for neuron in column})\n",
    "# print(len(neurons)) # 481334 as list\n",
    "#                     #  32796 as set\n",
    "\n",
    "# for idx, neuron in enumerate(neurons):\n",
    "#     if idx % 1000 == 0:\n",
    "#         print(idx)\n",
    "#     for _key in neuron.keys:\n",
    "#         ar_sent_vecs[idx] = np.add(ar_sent_vecs[idx], d_head_keys[_key])\n",
    "                \n",
    "\n",
    "# ar_sent_vecs.shape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(ar_sent_vecs[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# class KMeans():\n",
    "#     def compute_clusters(self, X, centers):\n",
    "#         return np.argmin([np.linalg.norm(X-c, axis=1) for c in centers], axis=0)\n",
    "#     def compute_centers(self, X, clusters):\n",
    "#         return np.array([X[clusters == c,].mean(0) for c in set(clusters)])\n",
    "#     def fit(self, X, k, n_iter=100):\n",
    "#         print('A')\n",
    "#         clusters = self.compute_clusters(X, np.array(random.sample(list(X), k)))\n",
    "#         for idx in range(n_iter):\n",
    "#             print(idx)\n",
    "#             #if idx % 10 == 0: print(idx)\n",
    "#             centers = self.compute_centers(X, clusters)\n",
    "#             clusters = self.compute_clusters(X, centers)\n",
    "#         return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "#               [4, 2], [4, 4], [4, 0]])\n",
    "# kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "# kmeans.labels_\n",
    "# #> array([0, 0, 0, 1, 1, 1], dtype=int32)\n",
    "# kmeans.predict([[0, 0], [4, 4]])\n",
    "# #> array([0, 1], dtype=int32)\n",
    "# kmeans.cluster_centers_\n",
    "# #> array([[ 1.,  2.],\n",
    "# #>     [ 4.,  2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time\n",
    "# clusters = KMeans(n_clusters=64, random_state=0).fit(ar_sent_vecs[:2000])\n",
    "# clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters.labels_[200:300]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
