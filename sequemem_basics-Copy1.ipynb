{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, key, sequence):\n",
    "        self.key = key\n",
    "        self.sequence = sequence\n",
    "        self.next = []\n",
    "        self.last = []\n",
    "\n",
    "    def link_nexts(self, n_next):\n",
    "        self.next.append(n_next)\n",
    "        self.next = list(set(self.next))\n",
    "        #n_next.link_last(self)\n",
    "        #self.last = list(set(self.last))\n",
    "    \n",
    "    def link_last(self, n_last):\n",
    "        self.last.append(n_last)\n",
    "    \n",
    "    def set_sequence(self, sequence):\n",
    "        self.sequence = sequence\n",
    "    def __repr__(self):\n",
    "        return \"<neuron: {}>\".format(self.key)\n",
    "        \n",
    "class Sequemem:\n",
    "    def __init__(self, uuid):\n",
    "        self.uuid = uuid\n",
    "        self.layer = defaultdict(list)\n",
    "        self.n_init = Neuron('<start>', '<start>')\n",
    "        self.predicted = []\n",
    "        self.active = []\n",
    "        self.sdr = []\n",
    "        self.sdr_predicted = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.predicted = []\n",
    "        self.active = []\n",
    "        self.active.append(self.n_init)\n",
    "        self.predicted.extend(self.n_init.next)\n",
    "        self.sdr_predicted = []\n",
    "        self.sdr = []\n",
    "    \n",
    "    def predict(self, str_sentence):\n",
    "        self.reset()\n",
    "        words = self.get_word_array(str_sentence)\n",
    "        \n",
    "        for idx, word in enumerate(words):\n",
    "            if self.hit(word, words, idx):\n",
    "                continue\n",
    "            else: break\n",
    "                \n",
    "        self.predicted = list(set(self.predicted))\n",
    "        self.active    = list(set(self.active))\n",
    "        self.sdr           = [neuron.sequence for neuron in self.active]\n",
    "        self.sdr_predicted = [neuron.key      for neuron in self.predicted]\n",
    "        return self.sdr_predicted\n",
    "            \n",
    "        \n",
    "    def get_word_array(self, str_sentence):\n",
    "        return re.compile(r'\\w+').findall(str_sentence)\n",
    "    def wrap_words(self, str_sentence):\n",
    "        str_sentence.insert(0, '<start>')\n",
    "        return str_sentence\n",
    "    \n",
    "    def hit(self, word, words, idx):\n",
    "        # Clear registers, and save the state as last \n",
    "        last_active = self.active[:]\n",
    "        self.active = []\n",
    "        last_predicted = self.predicted[:]\n",
    "        self.predicted = []\n",
    "        \n",
    "        while len(last_predicted) > 0:\n",
    "            neuron = last_predicted.pop()\n",
    "            if neuron.key == word:\n",
    "                # we  have at least one neuron predictive match\n",
    "                self.active.append(neuron)\n",
    "                self.active = list(set(self.active))\n",
    "                if len(neuron.next) > 0:\n",
    "                    self.predicted.extend(neuron.next)\n",
    "                    self.predicted = list(set(self.predicted))\n",
    "            \n",
    "        if len(self.active) == 0:\n",
    "            neuron =  Neuron(word, \"#\".join(words[:(idx+1)]))\n",
    "            self.layer[word] = neuron\n",
    "            for n in last_active:\n",
    "                n.link_nexts(neuron)\n",
    "                self.active.append(neuron)       \n",
    "\n",
    "        # IF we have any predicts, we're good, else signal end\n",
    "        return True if len(self.active) > 0 else False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"uuid: {}\\nn_init: {}\\npredicted: {}\\nactive: {}\\nsdr: {}\\nsdr_predicted: {}\".format(\n",
    "            self.uuid,\n",
    "            self.n_init,\n",
    "            self.predicted,\n",
    "            self.active,\n",
    "            self.sdr,\n",
    "            self.sdr_predicted\n",
    "        )          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', '22']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = Sequemem('adz')\n",
    "seq.get_word_array(\"The quick brown fox 22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uuid: adz\n",
      "n_init: <neuron: <start>>\n",
      "predicted: []\n",
      "active: [<neuron: fine>]\n",
      "sdr: ['Every#good#boy#does#fine']\n",
      "sdr_predicted: []\n",
      "All Good!\n"
     ]
    }
   ],
   "source": [
    "assert seq.predict(\"The quick brown fox\") == []\n",
    "\n",
    "assert seq.predict(\"The quick\")           == ['brown']\n",
    "assert seq.predict(\"The quick\")           == ['brown']\n",
    "assert seq.predict(\"The quick\")           == ['brown']\n",
    "assert seq.sdr                            == ['The#quick']\n",
    "assert seq.sdr_predicted                  == ['brown']\n",
    "\n",
    "assert seq.predict(\"The quick brown\")     == ['fox']\n",
    "assert seq.predict(\"The quick brown fox\") == []\n",
    "assert seq.predict(\"The quick brown\")     == ['fox']\n",
    "assert seq.predict(\"The quick brown\")     == ['fox']\n",
    "assert seq.predict(\"Every good boy does fine\")   == []\n",
    "print(seq)\n",
    "assert seq.predict(\"Every\")                      == ['good']\n",
    "print(\"All Good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'Every': <neuron: Every>,\n",
       "             'The': <neuron: The>,\n",
       "             'boy': <neuron: boy>,\n",
       "             'brown': <neuron: brown>,\n",
       "             'does': <neuron: does>,\n",
       "             'fine': <neuron: fine>,\n",
       "             'fox': <neuron: fox>,\n",
       "             'good': <neuron: good>,\n",
       "             'quick': <neuron: quick>})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.predict(\"Every\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'Every': <neuron: Every>,\n",
       "             'The': <neuron: The>,\n",
       "             'boy': <neuron: boy>,\n",
       "             'brown': <neuron: brown>,\n",
       "             'does': <neuron: does>,\n",
       "             'fine': <neuron: fine>,\n",
       "             'fox': <neuron: fox>,\n",
       "             'good': <neuron: good>,\n",
       "             'quick': <neuron: quick>})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<neuron: good>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.predicted = list(set(seq.predicted))\n",
    "seq.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = seq.predict(\"The quick brown fox\")\n",
    "v1 = seq.sdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = seq.predict(\"Every good boy does fine\")\n",
    "v2 = seq.sdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The#quick#brown#fox', 'Every#good#boy#does#fine']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[].extend(v1)\n",
    "v1.extend(v2)\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "def save_compare_freqs_to_file(window_size, ratio=0.9, cutoff=25):\n",
    "    w = str(window_size)\n",
    "    r = str(ratio).replace('.', '_')\n",
    "    c = str(cutoff)\n",
    "    with open('word_compare_freqs_size_{}_ratio_{}_cutoff_{}.csv'.format(w, r,c), 'w') as target:\n",
    "        for word in layer.d_w_uber_freq.keys():\n",
    "            lst_wrds = layer.comparison_frequencies(word, window_size=window_size,ratio=ratio, cutoff=cutoff)[2]\n",
    "            target.write(\"{}\\t{}\\n\".format(word, \"\\t\".join(lst_wrds)))\n",
    "\n",
    "save_compare_freqs_to_file(15)            \n",
    "print(\"All Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict loaded!\n"
     ]
    }
   ],
   "source": [
    "def load_word_from_line(line, d):\n",
    "    \"\"\"asume tab separated lines\"\"\"\n",
    "    words = line.split('\\t')\n",
    "    d[words.pop(0)] = words\n",
    "        \n",
    "word_5 = {}\n",
    "with open('word_compare_freqs_size_15_ratio_0_9_cutoff_25.csv', 'r') as source:\n",
    "    for line in source:\n",
    "        load_word_from_line(line, word_5)\n",
    "\n",
    "print(\"dict loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_local(lst1, lst2):\n",
    "    \"\"\"Calculate jaccard distance between two words from their graphical representation\n",
    "    as calculated with window_size and ratio.  Keep the number of cutoff words for the calculation.\n",
    "    Args:\n",
    "        w1: string, the first word for comparison\n",
    "        w2: string, the second word for comparison\n",
    "        window_size: int, go +- this number of words to calculate frequencies for graphical calc.\n",
    "        ratio: float, use this as cutoff in graphical calculation\n",
    "        cutoff: int, from graphical calculation, keep this number of words, the jaccard distance\n",
    "                is then calculated as the overlap of these two sets.\n",
    "    \"\"\"\n",
    "\n",
    "    u = len(set(lst1).union(set(lst2))) + 0.0000000001\n",
    "    i = len(set(lst1).intersection(set(lst2)))\n",
    "    return float(i)/float(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "across 0.5294117647043253\n",
      "ali 0.5294117647043253\n",
      "baba 0.5294117647043253\n",
      "looked 0.5294117647043253\n",
      "mustapha 0.5294117647043253\n",
      "perceiving 0.5294117647043253\n",
      "trying 0.5294117647043253\n"
     ]
    }
   ],
   "source": [
    "bust = 0\n",
    "threshold = 0.50\n",
    "w1 = 'morgiana'\n",
    "w1nbors = word_5[w1]\n",
    "best_matches = []\n",
    "for word, nbors in word_5.items():\n",
    "\n",
    "    if word == w1:\n",
    "        continue\n",
    "\n",
    "    score = jaccard_local(nbors, w1nbors)\n",
    "    if score > threshold:\n",
    "        print(word,score)\n",
    "        best_matches.append((word,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 3574),\n",
       " ('of', 1184),\n",
       " ('and', 431),\n",
       " ('henry', 402),\n",
       " ('richard', 277),\n",
       " ('edward', 149),\n",
       " ('john', 124),\n",
       " ('said', 118),\n",
       " ('s', 112),\n",
       " ('that', 103)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.get_counts_for_specific_key(key='king', window_size=2, direction=1).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wolf', 'father', 'mother', 'lone', 'sir', 'pack', 'ran', 'whose', 'seeonee', 's', 'replied', 'ravenous', 'got', 'shook', 'sleeping', 'stole']\n",
      "['wolf', 'a', 'said', 'father', 'mother', 'or', 'lone', 'sir', 'replied', 'pack', 'ran', 'dead', 'himself', 'lay', 'fox', 'whose']\n",
      "['wolf', 'a', 'said', 'father', 'mother', 'had', 'or', 'would', 'fox', 'lone', 'sir', 'replied', 'pack', 'himself', 'ran', 'bear']\n",
      "['wolf', 'the', 'a', 'said', 'father', 'had', 'mother', 'would', 'fox', 'or', 'lone', 'pack', 'into', 'sir', 'replied', 'himself']\n",
      "['wolf', 'the', 'a', 'said', 'father', 'had', 'mother', 'would', 'fox', 'or', 'if', 'up', 'who', 'pack', 'lone', 'sheep']\n",
      "['the', 'wolf', 'a', 'said', 'as', 'father', 'had', 'mother', 'would', 'or', 'fox', 'if', 'up', 'who', 'pack', 'sheep']\n",
      "['the', 'wolf', 'a', 'his', 'said', 'as', 'father', 'had', 'was', 'would', 'mother', 'fox', 'or', 'if', 'at', 'up']\n",
      "['the', 'wolf', 'a', 'to', 'he', 'his', 'said', 'as', 'had', 'was', 'father', 'but', 'mother', 'or', 'fox', 'would']\n",
      "['the', 'wolf', 'a', 'to', 'in', 'he', 'his', 'said', 'as', 'was', 'had', 'father', 'but', 'mother', 'would', 'or']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'in', 'his', 'said', 'as', 'you', 'was', 'had', 'but', 'him', 'father']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'in', 'his', 'said', 'as', 'was', 'you', 'had', 'but', 'him', 'father']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'in', 'his', 'that', 'said', 'as', 'you', 'with', 'was', 'not', 'but']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'in', 'his', 'that', 'said', 'as', 'was', 'you', 'with', 'not', 'but']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'his', 'in', 'that', 'said', 'as', 'with', 'was', 'you', 'not', 'for']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'his', 'in', 'that', 'said', 'as', 'was', 'with', 'you', 'not', 'for']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'his', 'in', 'that', 'said', 'as', 'was', 'with', 'not', 'you', 'for']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'his', 'in', 'that', 'said', 'was', 'as', 'with', 'not', 'you', 'for']\n",
      "['the', 'wolf', 'and', 'a', 'to', 'he', 'his', 'in', 'that', 'said', 'was', 'as', 'with', 'not', 'you', 'but']\n"
     ]
    }
   ],
   "source": [
    "for idx in range(2,20):\n",
    "    print(layer.comparison_frequencies('wolf',window_size=idx,ratio=0.9,cutoff=15)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39598\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'jaccard' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3726c3e12d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frequency_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_wdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_wdx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwindow_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jaccard' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#layer.get_counts_for_specific_key('fox').most_common()\n",
    "layer.window_size = 1\n",
    "layer.get_frequency_dict()\n",
    "\n",
    "cutoff = 100\n",
    "ratio = 0.25\n",
    "window_range = [10,15]\n",
    "w1 = 'god'\n",
    "w2 = 'jesus'\n",
    "print(len(layer.get_frequency_dict()[1]))\n",
    "\n",
    "profile = [jaccard(w1, w2, _w=_wdx, _c=cutoff, _r=ratio) for _wdx in window_range];\n",
    "print(profile)\n",
    "plt.axis([0, len(window_range), 0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 100\n",
    "ratio = 0.15\n",
    "window_range = 10\n",
    "w1 = 'queen'\n",
    "_,_,lst = layer.comparison_frequencies(w1, window_size=window_range,ratio=ratio, cutoff=cutoff)\n",
    "print(lst[:10])\n",
    "words = layer.get_frequency_dict()[1].keys()\n",
    "print(len(words))\n",
    "high = 0\n",
    "best_matches = []\n",
    "bust = 0\n",
    "threshold = 0.019\n",
    "for word in words:\n",
    "    bust += 1\n",
    "    if word == w1:\n",
    "        continue\n",
    "\n",
    "    score = jaccard(w1, word, _w=window_range, _c=cutoff, _r=ratio)\n",
    "    if bust % 10000 == 0: print(\"progress: \",bust)\n",
    "    if score > threshold:\n",
    "        print(word,score)\n",
    "        best_matches.append((word,score))\n",
    "        \n",
    "print(\"Best match is {} with a score of {}\".format(best_match, high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(len(layer.get_frequency_dict()[1]))\n",
    "a = np.random.random((128, 128))\n",
    "plt.imshow(a, cmap='hot', interpolation='nearest')\n",
    "plt.show()\n",
    "layer.get_frequency_dict()[1][\"Jesus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.get_frequency_dict()[1][\"Jesus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['a','b','c']\n",
    "var = l.pop(0)\n",
    "r = l[:]\n",
    "l.pop(0)\n",
    "l\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt, dct = layer.initialize_frequency_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison_frequencies\n",
    "layer.comparison_frequencies('men', ratio=0.5, cutoff=50, visualize_it=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.get_counts_for_specific_key('love').most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head_keys = layer.columns.keys()\n",
    "# neurons = list({neuron for column in layer.columns.values() for neuron in column})\n",
    "# one_hot_raw = np.eye(len(head_keys), dtype=int)\n",
    "# len(one_hot_raw)\n",
    "# d_head_keys = {}\n",
    "# for idx, word in enumerate(head_keys):\n",
    "#     d_head_keys[word] = one_hot_raw[idx]\n",
    "# len(d_head_keys)\n",
    "# ar_sent_vecs = np.zeros((len(neurons),len(head_keys)))\n",
    "# ar_sent_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headkeys = layer.columns.keys()\n",
    "# neurons = list({neuron for column in layer.columns.values() for neuron in column})\n",
    "# print(len(neurons)) # 481334 as list\n",
    "#                     #  32796 as set\n",
    "\n",
    "# for idx, neuron in enumerate(neurons):\n",
    "#     if idx % 1000 == 0:\n",
    "#         print(idx)\n",
    "#     for _key in neuron.keys:\n",
    "#         ar_sent_vecs[idx] = np.add(ar_sent_vecs[idx], d_head_keys[_key])\n",
    "                \n",
    "\n",
    "# ar_sent_vecs.shape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(ar_sent_vecs[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# class KMeans():\n",
    "#     def compute_clusters(self, X, centers):\n",
    "#         return np.argmin([np.linalg.norm(X-c, axis=1) for c in centers], axis=0)\n",
    "#     def compute_centers(self, X, clusters):\n",
    "#         return np.array([X[clusters == c,].mean(0) for c in set(clusters)])\n",
    "#     def fit(self, X, k, n_iter=100):\n",
    "#         print('A')\n",
    "#         clusters = self.compute_clusters(X, np.array(random.sample(list(X), k)))\n",
    "#         for idx in range(n_iter):\n",
    "#             print(idx)\n",
    "#             #if idx % 10 == 0: print(idx)\n",
    "#             centers = self.compute_centers(X, clusters)\n",
    "#             clusters = self.compute_clusters(X, centers)\n",
    "#         return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "#               [4, 2], [4, 4], [4, 0]])\n",
    "# kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "# kmeans.labels_\n",
    "# #> array([0, 0, 0, 1, 1, 1], dtype=int32)\n",
    "# kmeans.predict([[0, 0], [4, 4]])\n",
    "# #> array([0, 1], dtype=int32)\n",
    "# kmeans.cluster_centers_\n",
    "# #> array([[ 1.,  2.],\n",
    "# #>     [ 4.,  2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time\n",
    "# clusters = KMeans(n_clusters=64, random_state=0).fit(ar_sent_vecs[:2000])\n",
    "# clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters.labels_[200:300]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
