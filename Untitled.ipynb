{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3\n",
    "import sys\n",
    "sys.path.append(\"./sequemem\")\n",
    "from neuron import *\n",
    "from sequemem import *\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('starting: ', 'data/00_clean/sent_alice_in_wonderland.txt')\n",
      "0\n",
      "1000\n",
      "('starting: ', 'data/00_clean/sent_andersens_fairy_tales_pg1597.txt')\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "('starting: ', 'data/00_clean/sent_cats_of_ulthar.txt')\n",
      "0\n",
      "('starting: ', 'data/00_clean/sent_fairy_tales.txt')\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "('starting: ', 'data/00_clean/sent_grimms_fairy_tales.txt')\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "('starting: ', 'data/00_clean/sent_iris_fairy_tales.txt')\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "('starting: ', 'data/00_clean/sent_jungle_book_236-0.txt')\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "('starting: ', 'data/00_clean/sent_king_james_bible.txt')\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "('starting: ', 'data/00_clean/sent_shakespear.txt')\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "('starting: ', 'data/00_clean/sent_tao_te_king.txt')\n",
      "0\n",
      "1000\n",
      "('starting: ', 'data/00_clean/sent_the_prince.txt')\n",
      "0\n",
      "1000\n",
      "('starting: ', 'data/00_clean/sent_thousand_and_one.txt')\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "('starting: ', 'data/00_clean/sents_fables_la_fontaine.txt')\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "layer = Sequemem()\n",
    "\n",
    "files = [\n",
    "    'data/00_clean/sent_alice_in_wonderland.txt',\n",
    "    'data/00_clean/sent_andersens_fairy_tales_pg1597.txt',\n",
    "    'data/00_clean/sent_cats_of_ulthar.txt',\n",
    "    'data/00_clean/sent_fairy_tales.txt',\n",
    "    'data/00_clean/sent_grimms_fairy_tales.txt',\n",
    "    'data/00_clean/sent_iris_fairy_tales.txt',\n",
    "    'data/00_clean/sent_jungle_book_236-0.txt',\n",
    "    'data/00_clean/sent_king_james_bible.txt',\n",
    "    'data/00_clean/sent_shakespear.txt',\n",
    "    'data/00_clean/sent_tao_te_king.txt',\n",
    "    'data/00_clean/sent_the_prince.txt',\n",
    "    'data/00_clean/sent_thousand_and_one.txt',\n",
    "    'data/00_clean/sents_fables_la_fontaine.txt',\n",
    "]\n",
    "\n",
    "for f in files:\n",
    "    print(\"starting: \", f)\n",
    "    layer.train_from_file_group_line(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt, dct = layer.initialize_frequency_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Count for ', 'men', ' is ', 3114)\n",
      "Going to start visual with ['men', 'thousand', 'women', 'mighty', 'slew', 'valour', 'inhabitants', 'captains', 'benjamin', 'castruccio', 'shechem', 'gibeah', 'armed', 'horsemen', 'ai', 'rulers', 'asses', 'band', 'ishmael', 'mouths', 'assembled', 'abimelech', 'gedaliah', 'nethaniah', 'experience', 'abner', 'fourscore', 'hundreds', 'actions', 'belial', 'ulster', 'aged', 'forsook', 'backs', 'multitudes', 'sinigalia', 'skilful', 'oliverotto', 'mizpah', 'jabesh', 'ahikam', 'ordinary', 'virgins', 'jabeshgilead', 'succoth', 'uproar', 'faery', 'keilah', 'difficulties', 'examples', 'orsini']\n"
     ]
    }
   ],
   "source": [
    "# comparison_frequencies\n",
    "layer.comparison_frequencies('men', ratio=0.5, cutoff=50, visualize_it=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 2494),\n",
       " ('and', 1326),\n",
       " ('the', 1079),\n",
       " ('i', 1073),\n",
       " ('to', 1026),\n",
       " ('of', 1006),\n",
       " ('in', 839),\n",
       " ('that', 835),\n",
       " ('my', 772),\n",
       " ('for', 626),\n",
       " ('a', 621),\n",
       " ('not', 563),\n",
       " ('with', 548),\n",
       " ('you', 536),\n",
       " ('is', 533),\n",
       " ('but', 497),\n",
       " ('me', 495),\n",
       " ('as', 392),\n",
       " ('be', 385),\n",
       " ('his', 365),\n",
       " ('it', 364),\n",
       " ('he', 348),\n",
       " ('this', 341),\n",
       " ('so', 339),\n",
       " ('her', 329),\n",
       " ('all', 306),\n",
       " ('your', 303),\n",
       " ('him', 296),\n",
       " ('have', 294),\n",
       " ('thy', 289),\n",
       " ('thou', 274),\n",
       " ('do', 274),\n",
       " ('if', 269),\n",
       " ('thee', 264),\n",
       " ('will', 260),\n",
       " ('by', 233),\n",
       " ('which', 223),\n",
       " ('she', 205),\n",
       " ('from', 200),\n",
       " ('shall', 195),\n",
       " ('no', 188),\n",
       " ('than', 187),\n",
       " ('when', 182),\n",
       " ('on', 181),\n",
       " ('was', 168),\n",
       " ('more', 166),\n",
       " ('what', 166),\n",
       " ('can', 160),\n",
       " ('are', 159),\n",
       " ('or', 155),\n",
       " ('o', 151),\n",
       " ('hath', 143),\n",
       " ('then', 142),\n",
       " ('lord', 141),\n",
       " ('heart', 140),\n",
       " ('they', 140),\n",
       " ('now', 138),\n",
       " ('would', 136),\n",
       " ('one', 135),\n",
       " ('their', 133),\n",
       " ('them', 127),\n",
       " ('we', 125),\n",
       " ('let', 123),\n",
       " ('our', 121),\n",
       " ('at', 120),\n",
       " ('upon', 119),\n",
       " ('did', 119),\n",
       " ('may', 118),\n",
       " ('make', 117),\n",
       " ('am', 114),\n",
       " ('an', 113),\n",
       " ('who', 109),\n",
       " ('good', 108),\n",
       " ('yet', 107),\n",
       " ('had', 106),\n",
       " ('know', 104),\n",
       " ('god', 102),\n",
       " ('such', 101),\n",
       " ('there', 101),\n",
       " ('how', 100),\n",
       " ('like', 100),\n",
       " ('much', 98),\n",
       " ('man', 96),\n",
       " ('say', 95),\n",
       " ('should', 95),\n",
       " ('well', 92),\n",
       " ('mine', 92),\n",
       " ('us', 90),\n",
       " ('were', 86),\n",
       " ('fair', 85),\n",
       " ('true', 85),\n",
       " ('said', 85),\n",
       " ('hate', 83),\n",
       " ('life', 81),\n",
       " ('see', 80),\n",
       " ('come', 80),\n",
       " ('doth', 79),\n",
       " ('nor', 79),\n",
       " ('unto', 78),\n",
       " ('father', 77)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.get_counts_for_specific_key('love').most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head_keys = layer.columns.keys()\n",
    "# neurons = list({neuron for column in layer.columns.values() for neuron in column})\n",
    "# one_hot_raw = np.eye(len(head_keys), dtype=int)\n",
    "# len(one_hot_raw)\n",
    "# d_head_keys = {}\n",
    "# for idx, word in enumerate(head_keys):\n",
    "#     d_head_keys[word] = one_hot_raw[idx]\n",
    "# len(d_head_keys)\n",
    "# ar_sent_vecs = np.zeros((len(neurons),len(head_keys)))\n",
    "# ar_sent_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headkeys = layer.columns.keys()\n",
    "# neurons = list({neuron for column in layer.columns.values() for neuron in column})\n",
    "# print(len(neurons)) # 481334 as list\n",
    "#                     #  32796 as set\n",
    "\n",
    "# for idx, neuron in enumerate(neurons):\n",
    "#     if idx % 1000 == 0:\n",
    "#         print(idx)\n",
    "#     for _key in neuron.keys:\n",
    "#         ar_sent_vecs[idx] = np.add(ar_sent_vecs[idx], d_head_keys[_key])\n",
    "                \n",
    "\n",
    "# ar_sent_vecs.shape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(ar_sent_vecs[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# class KMeans():\n",
    "#     def compute_clusters(self, X, centers):\n",
    "#         return np.argmin([np.linalg.norm(X-c, axis=1) for c in centers], axis=0)\n",
    "#     def compute_centers(self, X, clusters):\n",
    "#         return np.array([X[clusters == c,].mean(0) for c in set(clusters)])\n",
    "#     def fit(self, X, k, n_iter=100):\n",
    "#         print('A')\n",
    "#         clusters = self.compute_clusters(X, np.array(random.sample(list(X), k)))\n",
    "#         for idx in range(n_iter):\n",
    "#             print(idx)\n",
    "#             #if idx % 10 == 0: print(idx)\n",
    "#             centers = self.compute_centers(X, clusters)\n",
    "#             clusters = self.compute_clusters(X, centers)\n",
    "#         return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "#               [4, 2], [4, 4], [4, 0]])\n",
    "# kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "# kmeans.labels_\n",
    "# #> array([0, 0, 0, 1, 1, 1], dtype=int32)\n",
    "# kmeans.predict([[0, 0], [4, 4]])\n",
    "# #> array([0, 1], dtype=int32)\n",
    "# kmeans.cluster_centers_\n",
    "# #> array([[ 1.,  2.],\n",
    "# #>     [ 4.,  2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time\n",
    "# clusters = KMeans(n_clusters=64, random_state=0).fit(ar_sent_vecs[:2000])\n",
    "# clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters.labels_[200:300]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
